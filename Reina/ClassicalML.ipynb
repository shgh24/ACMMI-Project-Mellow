{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adcd667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut, learning_curve\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.base import clone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FINAL_DIR = \"\"\n",
    "SESSION_DATA_DIR = \"\"\n",
    "VIZ_DIR = \"\"\n",
    "FEATURE_DIR = os.path.join(DATA_FINAL_DIR, \"Extracted_Features_Final\")\n",
    "FIG_DIR = os.path.join(VIZ_DIR, \"Bilateral_Analysis_Figures\")\n",
    "os.makedirs(FIG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0165c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = pd.read_csv(os.path.join(FEATURE_DIR, \"features_eda.csv\"))\n",
    "df_hr = pd.read_csv(os.path.join(FEATURE_DIR, \"features_hr.csv\"))\n",
    "df_temp = pd.read_csv(os.path.join(FEATURE_DIR, \"features_temp.csv\"))\n",
    "df_acc = pd.read_csv(os.path.join(FEATURE_DIR, \"features_acc.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5d6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hands1 = pd.read_csv(os.path.join(SESSION_DATA_DIR, \"hands1.csv\"))\n",
    "df_hands2 = pd.read_csv(os.path.join(SESSION_DATA_DIR, \"hands2.csv\"))\n",
    "\n",
    "hands1 = df_hands1[[\"Molly ID\", \"dominant\"]].copy()\n",
    "hands2 = df_hands2[[\"Molly ID\", \"dominant\"]].copy()\n",
    "\n",
    "df_handedness = pd.concat([hands1, hands2], ignore_index=True)\n",
    "df_handedness.columns = [\"participant_id\", \"dominant_hand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915cc8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_handedness(x):\n",
    "    if pd.isna(x):\n",
    "        return \"unknown\"\n",
    "    x = str(x).lower().strip()\n",
    "    if \"left\" in x:\n",
    "        return \"left\"\n",
    "    elif \"right\" in x:\n",
    "        return \"right\"\n",
    "    elif \"no participant\" in x:\n",
    "        return \"excluded\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "df_handedness[\"dominant_hand\"] = df_handedness[\"dominant_hand\"].apply(\n",
    "    standardize_handedness\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(df_handedness[\"dominant_hand\"].value_counts())\n",
    "print(\"handedness:\")\n",
    "print(df_handedness.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa3812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_phase_category(phase):\n",
    "    if phase == \"Baseline\":\n",
    "        return \"Baseline\"\n",
    "    elif phase in [\"Descriptive_Stress\", \"Stroop_Stress\", \"Math_Stress\"]:\n",
    "        return \"Stress\"\n",
    "    elif phase == \"MollyIntervention\":\n",
    "        return \"Intervention\"\n",
    "    elif phase == \"Post-Relaxation\":\n",
    "        return \"Relaxation\"\n",
    "    else:\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fca5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_eda, df_hr, df_temp, df_acc]:\n",
    "    df[\"phase_category\"] = df[\"phase\"].apply(map_phase_category)\n",
    "\n",
    "\n",
    "handedness_dict = dict(\n",
    "    zip(df_handedness[\"participant_id\"], df_handedness[\"dominant_hand\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a56f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_wrist_type(row, handedness_dict):\n",
    "    participant = row[\"participant_id\"]\n",
    "    side = row[\"side\"]\n",
    "    handedness = handedness_dict.get(participant, \"unknown\")\n",
    "\n",
    "    if handedness == \"right\":\n",
    "        return \"dominant\" if side == \"RIGHT\" else \"non-dominant\"\n",
    "    elif handedness == \"left\":\n",
    "        return \"dominant\" if side == \"LEFT\" else \"non-dominant\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "for df in [df_eda, df_hr, df_temp, df_acc]:\n",
    "    df[\"handedness\"] = df[\"participant_id\"].map(handedness_dict)\n",
    "    df[\"wrist_type\"] = df.apply(\n",
    "        lambda row: map_wrist_type(row, handedness_dict), axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "valid_handedness = [\"right\", \"left\"]\n",
    "df_eda = df_eda[df_eda[\"handedness\"].isin(valid_handedness)].copy()\n",
    "df_hr = df_hr[df_hr[\"handedness\"].isin(valid_handedness)].copy()\n",
    "df_temp = df_temp[df_temp[\"handedness\"].isin(valid_handedness)].copy()\n",
    "df_acc = df_acc[df_acc[\"handedness\"].isin(valid_handedness)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd0c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_eda[\n",
    "    [\"participant_id\", \"side\", \"handedness\", \"wrist_type\"]\n",
    "].drop_duplicates()\n",
    "print(sample.head(10).to_string(index=False))\n",
    "\n",
    "\n",
    "\n",
    "print(df_eda[\"wrist_type\"].value_counts())\n",
    "\n",
    "\n",
    "print(df_eda[\"phase_category\"].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "eda_feature_cols = [c for c in df_eda.columns if c.startswith(\"eda_\")]\n",
    "hr_feature_cols = [c for c in df_hr.columns if c.startswith(\"hr_\")]\n",
    "temp_feature_cols = [c for c in df_temp.columns if c.startswith(\"temp_\")]\n",
    "acc_feature_cols = [c for c in df_acc.columns if c.startswith(\"acc_\")]\n",
    "\n",
    "print(\n",
    "    f\"Feature counts: EDA={len(eda_feature_cols)}, HR={len(hr_feature_cols)}, TEMP={len(temp_feature_cols)}, ACC={len(acc_feature_cols)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e339f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_features_map = {\n",
    "    \"EDA\": {\n",
    "        \"df\": df_eda,\n",
    "        \"features\": [\n",
    "            \"eda_scl_mean\",\n",
    "            \"eda_scr_rate\",\n",
    "            \"eda_phasic_mean\",\n",
    "            \"eda_scr_count\",\n",
    "            \"eda_slope\",\n",
    "        ],\n",
    "    },\n",
    "    \"HR\": {\"df\": df_hr, \"features\": [\"hr_mean\", \"hr_std\", \"hr_rmssd\", \"hr_pnn50\"]},\n",
    "    \"TEMP\": {\"df\": df_temp, \"features\": [\"temp_mean\", \"temp_slope\", \"temp_std\"]},\n",
    "    \"ACC\": {\n",
    "        \"df\": df_acc,\n",
    "        \"features\": [\"acc_enmo_mean\", \"acc_magnitude_mean\", \"acc_activity_level\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cce320",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilateral_results = []\n",
    "\n",
    "for signal, config in key_features_map.items():\n",
    "    df = config[\"df\"]\n",
    "    features = config[\"features\"]\n",
    "\n",
    "\n",
    "    for feature in features:\n",
    "        nondom_data = df[df[\"wrist_type\"] == \"non-dominant\"][feature].dropna()\n",
    "        dom_data = df[df[\"wrist_type\"] == \"dominant\"][feature].dropna()\n",
    "\n",
    "        if len(nondom_data) > 0 and len(dom_data) > 0:\n",
    "            stat, p_value = mannwhitneyu(nondom_data, dom_data, alternative=\"two-sided\")\n",
    "            sig = (\n",
    "                \"---\"\n",
    "                if p_value < 0.001\n",
    "                else \"--\" if p_value < 0.01 else \"-\" if p_value < 0.05 else \"\"\n",
    "            )\n",
    "\n",
    "            nondom_mean = nondom_data.mean()\n",
    "            dom_mean = dom_data.mean()\n",
    "            diff = nondom_mean - dom_mean\n",
    "            diff_pct = (\n",
    "                ((nondom_mean - dom_mean) / abs(dom_mean)) * 100 if dom_mean != 0 else 0\n",
    "            )\n",
    "\n",
    "            bilateral_results.append(\n",
    "                {\n",
    "                    \"signal\": signal,\n",
    "                    \"feature\": feature,\n",
    "                    \"nondom_mean\": nondom_mean,\n",
    "                    \"dom_mean\": dom_mean,\n",
    "                    \"diff (ND-D)\": diff,\n",
    "                    \"diff_pct\": diff_pct,\n",
    "                    \"p_value\": p_value,\n",
    "                    \"significant\": sig,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"  {feature:25s} NON-DOM={nondom_mean:10.4f}, DOM={dom_mean:10.4f}, diff={diff:+10.4f} ({diff_pct:+6.1f}%), p={p_value:.2e} {sig}\"\n",
    "            )\n",
    "\n",
    "df_bilateral = pd.DataFrame(bilateral_results)\n",
    "\n",
    "sig_features = df_bilateral[df_bilateral[\"significant\"] != \"\"]\n",
    "if len(sig_features) > 0:\n",
    "    print(f\"{len(sig_features)} big diffrences\")\n",
    "    for _, row in sig_features.iterrows():\n",
    "        higher = \"NON-DOM\" if row[\"diff\"] > 0 else \"DOM\"\n",
    "        print(\n",
    "            f\"  {row['feature']}: {higher} higherby {abs(row['diff_pct']):.1f}% (p={row['p_value']:.2e})\"\n",
    "        )\n",
    "else:\n",
    "    print(\"insignificant\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6dc716",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_order = [\"Baseline\", \"Stress\", \"Intervention\", \"Relaxation\"]\n",
    "\n",
    "stress_features_map = {\n",
    "    \"eda_scl_mean\": df_eda,\n",
    "    \"eda_phasic_mean\": df_eda,\n",
    "    \"eda_scr_rate\": df_eda,\n",
    "    \"hr_mean\": df_hr,\n",
    "    \"hr_rmssd\": df_hr,\n",
    "    \"temp_mean\": df_temp,\n",
    "    \"temp_slope\": df_temp,\n",
    "    \"acc_enmo_mean\": df_acc,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a950c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilateral_phase_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e02422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bilateral_phase = pd.DataFrame(bilateral_phase_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375eaa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in stress_features_map.keys():\n",
    "    feat_data = df_bilateral_phase[df_bilateral_phase[\"feature\"] == feature]\n",
    "\n",
    "    baseline_row = feat_data[feat_data[\"phase\"] == \"Baseline\"]\n",
    "    stress_row = feat_data[feat_data[\"phase\"] == \"Stress\"]\n",
    "\n",
    "    if len(baseline_row) > 0 and len(stress_row) > 0:\n",
    "        baseline_diff = baseline_row[\"diff_ND_D\"].values[0]\n",
    "        stress_diff = stress_row[\"diff_ND_D\"].values[0]\n",
    "\n",
    "        change = stress_diff - baseline_diff\n",
    "        change_direction = (\n",
    "            \"increased\" if abs(stress_diff) > abs(baseline_diff) else \"decreased\"\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"  {feature:20s}:bseline diff={baseline_diff:+.4f}, stress diff={stress_diff:+.4f}, change={change:+.4f} (asymmetry {change_direction})\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"  {feature:20s}: data missing\")\n",
    "\n",
    "df_bilateral_phase.to_csv(\n",
    "    os.path.join(FEATURE_DIR, \"bilateral_dominant_vs_nondominant_by_phase.csv\"),\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4222da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "phase_order = [\"Baseline\", \"Stress\", \"Intervention\", \"Relaxation\"]\n",
    "phase_colors = {\n",
    "    \"Baseline\": \"#2ecc71\",\n",
    "    \"Stress\": \"#e74c3c\",\n",
    "    \"Intervention\": \"#3498db\",\n",
    "    \"Relaxation\": \"#9b59b6\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc7072",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_features_map = {\n",
    "    \"eda_scl_mean\": df_eda,\n",
    "    \"eda_phasic_mean\": df_eda,\n",
    "    \"eda_scr_rate\": df_eda,\n",
    "    \"hr_mean\": df_hr,\n",
    "    \"hr_rmssd\": df_hr,\n",
    "    \"temp_mean\": df_temp,\n",
    "    \"temp_slope\": df_temp,\n",
    "    \"acc_enmo_mean\": df_acc,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3bd793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_comparison(df, feature_cols, signal_name):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    for ax, wrist_type in zip(axes[:2], [\"non-dominant\", \"dominant\"]):\n",
    "        df_subset = df[\n",
    "            (df[\"wrist_type\"] == wrist_type)\n",
    "            & (df[\"phase_category\"].isin([\"Baseline\", \"Stress\"]))\n",
    "        ].copy()\n",
    "\n",
    "        X = df_subset[feature_cols].dropna()\n",
    "        valid_idx = X.index\n",
    "        y = df_subset.loc[valid_idx, \"phase_category\"]\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\n",
    "        X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "        colors = {\"Baseline\": \"#2ecc71\", \"Stress\": \"#e74c3c\"}\n",
    "        for phase in [\"Baseline\", \"Stress\"]:\n",
    "            mask = y == phase\n",
    "            ax.scatter(\n",
    "                X_tsne[mask, 0],\n",
    "                X_tsne[mask, 1],\n",
    "                c=colors[phase],\n",
    "                label=phase,\n",
    "                alpha=0.6,\n",
    "                s=30,\n",
    "                edgecolor=\"white\",\n",
    "            )\n",
    "\n",
    "        ax.set_xlabel(\"tsne 1\")\n",
    "        ax.set_ylabel(\"tsne 2\")\n",
    "        ax.set_title(\n",
    "            f\"{wrist_type.upper()}\\n(n={len(X)})\", fontsize=11, fontweight=\"bold\"\n",
    "        )\n",
    "        ax.legend(loc=\"upper right\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "    ax3 = axes[2]\n",
    "    df_both = df[df[\"phase_category\"].isin([\"Baseline\", \"Stress\"])].copy()\n",
    "    X_both = df_both[feature_cols].dropna()\n",
    "    valid_idx = X_both.index\n",
    "    wrist_labels = df_both.loc[valid_idx, \"wrist_type\"]\n",
    "    phase_labels = df_both.loc[valid_idx, \"phase_category\"]\n",
    "\n",
    "    X_scaled_both = scaler.fit_transform(X_both)\n",
    "    tsne_both = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\n",
    "    X_tsne_both = tsne_both.fit_transform(X_scaled_both)\n",
    "\n",
    "\n",
    "    markers = {\"Baseline\": \"o\", \"Stress\": \"^\"}\n",
    "    colors_wrist = {\"non-dominant\": \"#3498db\", \"dominant\": \"#e74c3c\"}\n",
    "\n",
    "    for wrist in [\"non-dominant\", \"dominant\"]:\n",
    "        for phase in [\"Baseline\", \"Stress\"]:\n",
    "            mask = (wrist_labels == wrist) & (phase_labels == phase)\n",
    "            ax3.scatter(\n",
    "                X_tsne_both[mask, 0],\n",
    "                X_tsne_both[mask, 1],\n",
    "                c=colors_wrist[wrist],\n",
    "                marker=markers[phase],\n",
    "                label=f\"{wrist[:3].upper()}-{phase[:4]}\",\n",
    "                alpha=0.5,\n",
    "                s=30,\n",
    "                edgecolor=\"white\",\n",
    "            )\n",
    "\n",
    "    ax3.set_xlabel(\"tsne1\")\n",
    "    ax3.set_ylabel(\"tsne2\")\n",
    "    ax3.set_title(\n",
    "        \"bilateral\", fontsize=11, fontweight=\"bold\"\n",
    "    )\n",
    "    ax3.legend(loc=\"upper right\", fontsize=8)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"tsne for {signal_name}\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "for signal_name, df, feature_cols in signal_configs:\n",
    "    fig = plot_tsne_comparison(df, feature_cols, signal_name)\n",
    "    plt.savefig(\n",
    "        os.path.join(FIG_DIR, f\"tsne_{signal_name.lower()}_dominant_comparison.png\"),\n",
    "        dpi=150,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()\n",
    "    print(f\"Saved: tsne_{signal_name.lower()}_dominant_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ccbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(\n",
    "        n_neighbors=5,  \n",
    "        weights=\"uniform\", \n",
    "        metric=\"euclidean\",  \n",
    "        n_jobs=-1, \n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        kernel=\"rbf\", \n",
    "        C=1.0, \n",
    "        gamma=\"scale\",  \n",
    "        probability=True, \n",
    "        random_state=42,  \n",
    "    ),\n",
    "    \"XGBoost\": GradientBoostingClassifier(\n",
    "        n_estimators=100, \n",
    "        learning_rate=0.1, \n",
    "        max_depth=3, \n",
    "        min_samples_split=2,  \n",
    "        min_samples_leaf=1,  \n",
    "        subsample=1.0,  \n",
    "        random_state=42, \n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e59771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ml_data(\n",
    "    df, feature_cols, wrist_type=None, phase_pair=(\"Baseline\", \"Stress\")\n",
    "):\n",
    "    if wrist_type:\n",
    "        df_subset = df[df[\"wrist_type\"] == wrist_type].copy()\n",
    "    else:\n",
    "        df_subset = df.copy()\n",
    "\n",
    "    df_subset = df_subset[df_subset[\"phase_category\"].isin(phase_pair)].copy()\n",
    "\n",
    "    X = df_subset[feature_cols].copy()\n",
    "    y = (df_subset[\"phase_category\"] == phase_pair[1]).astype(int)  \n",
    "    \n",
    "    groups = df_subset[\"participant_id\"]\n",
    "    mask = ~X.isna().any(axis=1)\n",
    "    X, y, groups = X[mask], y[mask], groups[mask]\n",
    "\n",
    "    return X.values, y.values, groups.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29548640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loso(X, y, groups, model):\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    \n",
    "    y_prob_all = []\n",
    "    \n",
    "    participant_results = []\n",
    "    \n",
    "\n",
    "    for train_idx, test_idx in logo.split(X, y, groups):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        test_participant = groups[test_idx][0]\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        y_true_all.extend(y_test)\n",
    "        y_pred_all.extend(y_pred)\n",
    "        \n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "            y_prob_all.extend(y_prob)\n",
    "\n",
    "\n",
    "        participant_acc = accuracy_score(y_test, y_pred)\n",
    "        participant_results.append(\n",
    "            {\n",
    "                \"participant\": test_participant,\n",
    "                \"accuracy\": participant_acc,\n",
    "                \"n_samples\": len(y_test),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "    acc = accuracy_score(y_true_all, y_pred_all)\n",
    "    f1 = f1_score(y_true_all, y_pred_all, average=\"macro\")\n",
    "\n",
    "    if len(y_prob_all) > 0:\n",
    "        auc = roc_auc_score(y_true_all, y_prob_all)\n",
    "    else:\n",
    "        auc = np.nan\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1_macro\": f1,\n",
    "        \"auc\": auc,\n",
    "        \"y_true\": y_true_all,\n",
    "        \"y_pred\": y_pred_all,\n",
    "        \"y_prob\": y_prob_all,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"participant_results\": participant_results,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8572b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_configs = [\n",
    "    (\"EDA\", df_eda, eda_feature_cols),\n",
    "    (\"HR\", df_hr, hr_feature_cols),\n",
    "    (\"TEMP\", df_temp, temp_feature_cols),\n",
    "    (\"ACC\", df_acc, acc_feature_cols),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e9afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_exp1 = []\n",
    "\n",
    "for signal_name, df, feature_cols in signal_configs:\n",
    "    print(f\"{signal_name}: ({len(feature_cols)} features)\")\n",
    "\n",
    "    for wrist in [\"non-dominant\", \"dominant\"]:\n",
    "        X, y, groups = prepare_ml_data(\n",
    "            df, feature_cols, wrist_type=wrist, phase_pair=(\"Baseline\", \"Stress\")\n",
    "        )\n",
    "\n",
    "        n_participants = len(np.unique(groups))\n",
    "        n_samples = len(y)\n",
    "        n_baseline = sum(y == 0)\n",
    "        n_stress = sum(y == 1)\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            model_clone = clone(model)\n",
    "            result = evaluate_loso(X, y, groups, model_clone)\n",
    "\n",
    "            results_exp1.append(\n",
    "                {\n",
    "                    \"signal\": signal_name,\n",
    "                    \"wrist_type\": wrist,\n",
    "                    \"model\": model_name,\n",
    "                    \"accuracy\": result[\"accuracy\"],\n",
    "                    \"f1_macro\": result[\"f1_macro\"],\n",
    "                    \"auc\": result[\"auc\"],\n",
    "                    \"n_samples\": n_samples,\n",
    "                    \"n_participants\": n_participants,\n",
    "                    \"n_features\": len(feature_cols),\n",
    "                }\n",
    "            )\n",
    "            tn, fp, fn, tp = result[\"confusion_matrix\"].ravel()\n",
    "            sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "            print(\n",
    "                f\"    {model_name:10s}: Acc={result['accuracy']:.3f}, \"\n",
    "                f\"F1={result['f1_macro']:.3f}, AUC={result['auc']:.3f} \"\n",
    "                f\"(Sens={sensitivity:.2f}, Spec={specificity:.2f})\"\n",
    "            )\n",
    "\n",
    "df_results_exp1 = pd.DataFrame(results_exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf70947",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [\"accuracy\", \"f1_macro\", \"auc\"]:\n",
    "    pivot = df_results_exp1.pivot_table(\n",
    "        index=[\"signal\", \"model\"], columns=\"wrist_type\", values=metric\n",
    "    )\n",
    "    pivot[\"Diff\"] = pivot[\"non-dominant\"] - pivot[\"dominant\"]\n",
    "    pivot[\"Better\"] = pivot.apply(\n",
    "        lambda row: \"NON-DOM\" if row[\"Diff (ND-D)\"] > 0 else \"DOMINANT\", axis=1\n",
    "    )\n",
    "    print(pivot.round(3).to_string())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------\n",
    "for signal_name in [\"EDA\", \"HR\", \"TEMP\", \"ACC\"]:\n",
    "    signal_data = df_results_exp1[df_results_exp1[\"signal\"] == signal_name]\n",
    "\n",
    "    nondom_acc = signal_data[signal_data[\"wrist_type\"] == \"non-dominant\"][\n",
    "        \"accuracy\"\n",
    "    ].mean()\n",
    "    dom_acc = signal_data[signal_data[\"wrist_type\"] == \"dominant\"][\"accuracy\"].mean()\n",
    "\n",
    "    winner = \"NON-DOMINANT\" if nondom_acc > dom_acc else \"DOMINANT\"\n",
    "    diff = nondom_acc - dom_acc\n",
    "\n",
    "    print(\n",
    "        f\"  {signal_name}: NON-DOM={nondom_acc:.3f}, DOM={dom_acc:.3f}, Diff={diff:+.3f} â†’ {winner}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for signal_name in [\"EDA\", \"HR\", \"TEMP\", \"ACC\"]:\n",
    "    signal_data = df_results_exp1[df_results_exp1[\"signal\"] == signal_name]\n",
    "\n",
    "    model_winners = []\n",
    "    for model_name in [\"KNN\", \"SVM\", \"XGBoost\"]:\n",
    "        model_data = signal_data[signal_data[\"model\"] == model_name]\n",
    "        nondom_acc = model_data[model_data[\"wrist_type\"] == \"non-dominant\"][\n",
    "            \"accuracy\"\n",
    "        ].values[0]\n",
    "        dom_acc = model_data[model_data[\"wrist_type\"] == \"dominant\"][\"accuracy\"].values[\n",
    "            0\n",
    "        ]\n",
    "        model_winners.append(\"ND\" if nondom_acc > dom_acc else \"D\")\n",
    "\n",
    "    status = \"AGREE\" if len(set(model_winners)) == 1 else \"DISAGREE\"\n",
    "    print(\n",
    "        f\"  {signal_name}: {status} (KNN={model_winners[0]}, SVM={model_winners[1]}, XGB={model_winners[2]})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c80ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_participant_accuracies_single_signal(df, feature_cols, wrist_type, model):\n",
    "    X, y, groups = prepare_ml_data(df, feature_cols, wrist_type=wrist_type)\n",
    "\n",
    "    logo = LeaveOneGroupOut()\n",
    "    participant_accs = {}\n",
    "\n",
    "    for train_idx, test_idx in logo.split(X, y, groups):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        participant = groups[test_idx][0]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        model_clone = clone(model)\n",
    "        model_clone.fit(X_train_scaled, y_train)\n",
    "        y_pred = model_clone.predict(X_test_scaled)\n",
    "\n",
    "        participant_accs[participant] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return participant_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_agreement_results = []\n",
    "\n",
    "for signal_name, df, feature_cols in signal_configs:\n",
    "    print(f\"(signal_name}:\")\n",
    "\n",
    "    model_winners = {}\n",
    "    model_diffs = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        nd_accs = get_per_participant_accuracies_single_signal(\n",
    "            df, feature_cols, \"non-dominant\", model\n",
    "        )\n",
    "        d_accs = get_per_participant_accuracies_single_signal(\n",
    "            df, feature_cols, \"dominant\", model\n",
    "        )\n",
    "\n",
    "        nd_mean = np.mean(list(nd_accs.values()))\n",
    "        d_mean = np.mean(list(d_accs.values()))\n",
    "        diff = nd_mean - d_mean\n",
    "\n",
    "        winner = \"ND\" if diff > 0 else \"D\"\n",
    "        model_winners[model_name] = winner\n",
    "        model_diffs[model_name] = diff\n",
    "\n",
    "    unique_winners = set(model_winners.values())\n",
    "    if len(unique_winners) == 1:\n",
    "        agreement = \"FULL AGREEMENT\"\n",
    "        agreed_winner = list(unique_winners)[0]\n",
    "    else:\n",
    "        agreement = \"DISAGREEMENT\"\n",
    "        agreed_winner = \"Mixed\"\n",
    "\n",
    "\n",
    "#---------------------------------\n",
    "    model_agreement_results.append(\n",
    "        {\n",
    "            \"signal\": signal_name,\n",
    "            \"KNN_winner\": model_winners[\"KNN\"],\n",
    "            \"SVM_winner\": model_winners[\"SVM\"],\n",
    "            \"XGBoost_winner\": model_winners[\"XGBoost\"],\n",
    "            \"KNN_diff\": model_diffs[\"KNN\"],\n",
    "            \"SVM_diff\": model_diffs[\"SVM\"],\n",
    "            \"XGBoost_diff\": model_diffs[\"XGBoost\"],\n",
    "            \"agreement\": agreement,\n",
    "            \"consensus_winner\": agreed_winner,\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_model_agreement = pd.DataFrame(model_agreement_results)\n",
    "print(\n",
    "    df_model_agreement[\n",
    "        [\n",
    "            \"signal\",\n",
    "            \"KNN_winner\",\n",
    "            \"SVM_winner\",\n",
    "            \"XGBoost_winner\",\n",
    "            \"agreement\",\n",
    "            \"consensus_winner\",\n",
    "        ]\n",
    "    ].to_string(index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3502e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_window_index(df):\n",
    "    df = df.copy()\n",
    "    df[\"window_idx\"] = df.groupby([\"participant_id\", \"phase\", \"side\"]).cumcount()\n",
    "    return df\n",
    "\n",
    "df_eda_idx = add_window_index(df_eda)\n",
    "df_hr_idx = add_window_index(df_hr)\n",
    "df_temp_idx = add_window_index(df_temp)\n",
    "df_acc_idx = add_window_index(df_acc)\n",
    "\n",
    "print(\"\\nWindow indices added for signal alignment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eda_features = pd.read_csv(\"Extracted_Features_Final/features_eda.csv\")\n",
    "hr_features = pd.read_csv(\"Extracted_Features_Final/features_hr.csv\")\n",
    "temp_features = pd.read_csv(\"Extracted_Features_Final/features_temp.csv\")\n",
    "acc_features = pd.read_csv(\"Extracted_Features_Final/features_acc.csv\")\n",
    "metadata_cols = [\"participant_id\", \"timestamp\", \"phase\", \"window_start\", \"window_end\"]\n",
    "\n",
    "for name, df in [\n",
    "    (\"EDA\", eda_features),\n",
    "    (\"HR\", hr_features),\n",
    "    (\"TEMP\", temp_features),\n",
    "    (\"ACC\", acc_features),\n",
    "]:\n",
    "    feature_cols = [c for c in df.columns if c not in metadata_cols]\n",
    "    print(f\"{name}: {len(feature_cols)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c676f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_combined_features_single_wrist(\n",
    "    filter_col, filter_val, phase_pair=(\"Baseline\", \"Stress\")\n",
    "):\n",
    "\n",
    "    df_eda_f = df_eda_idx[\n",
    "        (df_eda_idx[filter_col] == filter_val)\n",
    "        & (df_eda_idx[\"phase_category\"].isin(phase_pair))\n",
    "    ].copy()\n",
    "    df_hr_f = df_hr_idx[\n",
    "        (df_hr_idx[filter_col] == filter_val)\n",
    "        & (df_hr_idx[\"phase_category\"].isin(phase_pair))\n",
    "    ].copy()\n",
    "    df_temp_f = df_temp_idx[\n",
    "        (df_temp_idx[filter_col] == filter_val)\n",
    "        & (df_temp_idx[\"phase_category\"].isin(phase_pair))\n",
    "    ].copy()\n",
    "    df_acc_f = df_acc_idx[\n",
    "        (df_acc_idx[filter_col] == filter_val)\n",
    "        & (df_acc_idx[\"phase_category\"].isin(phase_pair))\n",
    "    ].copy()\n",
    "\n",
    "\n",
    "    merge_cols = [\"participant_id\", \"phase_category\", \"phase\", \"side\", \"window_idx\"]\n",
    "\n",
    "    df_merged = (\n",
    "        df_eda_f[merge_cols + eda_feature_cols]\n",
    "        .merge(df_hr_f[merge_cols + hr_feature_cols], on=merge_cols, how=\"inner\")\n",
    "        .merge(df_temp_f[merge_cols + temp_feature_cols], on=merge_cols, how=\"inner\")\n",
    "        .merge(df_acc_f[merge_cols + acc_feature_cols], on=merge_cols, how=\"inner\")\n",
    "    )\n",
    "\n",
    "    all_feature_cols = (\n",
    "        eda_feature_cols + hr_feature_cols + temp_feature_cols + acc_feature_cols\n",
    "    )\n",
    "\n",
    "    X = df_merged[all_feature_cols].copy()\n",
    "    y = (df_merged[\"phase_category\"] == phase_pair[1]).astype(int)\n",
    "    groups = df_merged[\"participant_id\"]\n",
    "\n",
    "\n",
    "    mask = ~X.isna().any(axis=1)\n",
    "    X, y, groups = X[mask], y[mask], groups[mask]\n",
    "\n",
    "    return X.values, y.values, groups.values, all_feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2a = []\n",
    "\n",
    "for wrist_type in [\"non-dominant\", \"dominant\"]:\n",
    "    X, y, groups, feature_cols_all = prepare_combined_features_single_wrist(\n",
    "        \"wrist_type\", wrist_type\n",
    "    )\n",
    "    n_features = len(feature_cols_all)\n",
    "\n",
    "    print(\n",
    "        f\"\\n{wrist_type.upper()}: {len(y)} samples, {len(np.unique(groups))} participants, {n_features} features\"\n",
    "    )\n",
    "\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"  Running {model_name}...\", end=\" \", flush=True)\n",
    "        model_clone = clone(model)\n",
    "        result = evaluate_loso(X, y, groups, model_clone)\n",
    "\n",
    "        results_2a.append(\n",
    "            {\n",
    "                \"comparison\": \"DOM_vs_NONDOM\",\n",
    "                \"wrist\": wrist_type,\n",
    "                \"model\": model_name,\n",
    "                \"accuracy\": result[\"accuracy\"],\n",
    "                \"f1_macro\": result[\"f1_macro\"],\n",
    "                \"auc\": result[\"auc\"],\n",
    "                \"n_features\": n_features,\n",
    "                \"n_samples\": len(y),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        tn, fp, fn, tp = result[\"confusion_matrix\"].ravel()\n",
    "        sens = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        spec = tn / (tn + fp) if (tn + fp) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dom_nondom_results = [r for r in results_2a if r[\"comparison\"] == \"DOM_vs_NONDOM\"]\n",
    "for model_name in [\"KNN\", \"SVM\", \"XGBoost\"]:\n",
    "    nd_acc = [\n",
    "        r[\"accuracy\"]\n",
    "        for r in dom_nondom_results\n",
    "        if r[\"wrist\"] == \"non-dominant\" and r[\"model\"] == model_name\n",
    "    ][0]\n",
    "    d_acc = [\n",
    "        r[\"accuracy\"]\n",
    "        for r in dom_nondom_results\n",
    "        if r[\"wrist\"] == \"dominant\" and r[\"model\"] == model_name\n",
    "    ][0]\n",
    "    diff = nd_acc - d_acc\n",
    "    winner = \"ND\" if diff > 0 else \"D\"\n",
    "    print(\n",
    "        f\"  {model_name:10s}: ND={nd_acc:.3f}, D={d_acc:.3f}, Diff={diff:+.3f} -> {winner}\"\n",
    "    )\n",
    "\n",
    "nd_avg = np.mean(\n",
    "    [r[\"accuracy\"] for r in dom_nondom_results if r[\"wrist\"] == \"non-dominant\"]\n",
    ")\n",
    "d_avg = np.mean([r[\"accuracy\"] for r in dom_nondom_results if r[\"wrist\"] == \"dominant\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da81093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_bilateral_features(phase_pair=(\"Baseline\", \"Stress\")):\n",
    "    df_eda_nd = df_eda_idx[\n",
    "        (df_eda_idx[\"wrist_type\"] == \"non-dominant\")\n",
    "        & (df_eda_idx[\"phase_category\"].isin(phase_pair))\n",
    "    ].copy()\n",
    "    df_hr_nd = df_hr_idx[\n",
    "        (df_hr_idx[\"wrist_type\"] == \"non-dominant\")\n",
    "        & (df_hr_idx[\"phase_category\"].isin(phase_pair))\n",
    "    ].copy()\n",
    "    df_temp_nd = df_temp_idx[\n",
    "        (df_temp_idx[\"wrist_type\"] == \"non-dominant\")\n",
    "        & (df_temp_idx[\"phase_category\"].isin(phase_pair))\n",
    "    ].copy()\n",
    "    df_acc_nd = df_acc_idx[\n",
    "        (df_acc_idx[\"wrist_type\"] == \"non-dominant\")\n",
    "        & (df_acc_idx[\"phase_category\"].isin(phase_pair))\n",
    "    ].copy()\n",
    "\n",
    "#---------------------------------\n",
    "    df_eda_d = df_eda_idx[\n",
    "        (df_eda_idx[\"wrist_type\"] == \"dominant\")\n",
    "        & (df_eda_idx[\"phase_category\"].isin(phase_pair))\n",
    "    ].copy()\n",
    "    df_hr_d = df_hr_idx[\n",
    "        (df_hr_idx[\"wrist_type\"] == \"dominant\")\n",
    "        & (df_hr_idx[\"phase_category\"].isin(phase_pair))\n",
    "    ].copy()\n",
    "    df_temp_d = df_temp_idx[\n",
    "        (df_temp_idx[\"wrist_type\"] == \"dominant\")\n",
    "        & (df_temp_idx[\"phase_category\"].isin(phase_pair))\n",
    "    ].copy()\n",
    "    df_acc_d = df_acc_idx[\n",
    "        (df_acc_idx[\"wrist_type\"] == \"dominant\")\n",
    "        & (df_acc_idx[\"phase_category\"].isin(phase_pair))\n",
    "    ].copy()\n",
    "\n",
    "    eda_nd_rename = {c: f\"{c}_ND\" for c in eda_feature_cols}\n",
    "    hr_nd_rename = {c: f\"{c}_ND\" for c in hr_feature_cols}\n",
    "    temp_nd_rename = {c: f\"{c}_ND\" for c in temp_feature_cols}\n",
    "    acc_nd_rename = {c: f\"{c}_ND\" for c in acc_feature_cols}\n",
    "\n",
    "    eda_d_rename = {c: f\"{c}_D\" for c in eda_feature_cols}\n",
    "    hr_d_rename = {c: f\"{c}_D\" for c in hr_feature_cols}\n",
    "    temp_d_rename = {c: f\"{c}_D\" for c in temp_feature_cols}\n",
    "    acc_d_rename = {c: f\"{c}_D\" for c in acc_feature_cols}\n",
    "\n",
    "    df_eda_nd = df_eda_nd.rename(columns=eda_nd_rename)\n",
    "    df_hr_nd = df_hr_nd.rename(columns=hr_nd_rename)\n",
    "    df_temp_nd = df_temp_nd.rename(columns=temp_nd_rename)\n",
    "    df_acc_nd = df_acc_nd.rename(columns=acc_nd_rename)\n",
    "\n",
    "    df_eda_d = df_eda_d.rename(columns=eda_d_rename)\n",
    "    df_hr_d = df_hr_d.rename(columns=hr_d_rename)\n",
    "    df_temp_d = df_temp_d.rename(columns=temp_d_rename)\n",
    "    df_acc_d = df_acc_d.rename(columns=acc_d_rename)\n",
    "\n",
    "    #---------------------------------\n",
    "    merge_cols_nd = [\"participant_id\", \"phase_category\", \"phase\", \"window_idx\"]\n",
    "\n",
    "    nd_feature_cols = (\n",
    "        list(eda_nd_rename.values())\n",
    "        + list(hr_nd_rename.values())\n",
    "        + list(temp_nd_rename.values())\n",
    "        + list(acc_nd_rename.values())\n",
    "    )\n",
    "    d_feature_cols = (\n",
    "        list(eda_d_rename.values())\n",
    "        + list(hr_d_rename.values())\n",
    "        + list(temp_d_rename.values())\n",
    "        + list(acc_d_rename.values())\n",
    "    )\n",
    "\n",
    "#---------------------------------\n",
    "    df_nd_merged = (\n",
    "        df_eda_nd[merge_cols_nd + list(eda_nd_rename.values())]\n",
    "        .merge(\n",
    "            df_hr_nd[merge_cols_nd + list(hr_nd_rename.values())],\n",
    "            on=merge_cols_nd,\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        .merge(\n",
    "            df_temp_nd[merge_cols_nd + list(temp_nd_rename.values())],\n",
    "            on=merge_cols_nd,\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        .merge(\n",
    "            df_acc_nd[merge_cols_nd + list(acc_nd_rename.values())],\n",
    "            on=merge_cols_nd,\n",
    "            how=\"inner\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    #---------------------------------\n",
    "    df_d_merged = (\n",
    "        df_eda_d[merge_cols_nd + list(eda_d_rename.values())]\n",
    "        .merge(\n",
    "            df_hr_d[merge_cols_nd + list(hr_d_rename.values())],\n",
    "            on=merge_cols_nd,\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        .merge(\n",
    "            df_temp_d[merge_cols_nd + list(temp_d_rename.values())],\n",
    "            on=merge_cols_nd,\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        .merge(\n",
    "            df_acc_d[merge_cols_nd + list(acc_d_rename.values())],\n",
    "            on=merge_cols_nd,\n",
    "            how=\"inner\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "#---------------------------------\n",
    "    df_bilateral = df_nd_merged.merge(df_d_merged, on=merge_cols_nd, how=\"inner\")\n",
    "    bilateral_feature_cols = nd_feature_cols + d_feature_cols\n",
    "\n",
    "    X = df_bilateral[bilateral_feature_cols].copy()\n",
    "    y = (df_bilateral[\"phase_category\"] == phase_pair[1]).astype(int)\n",
    "    groups = df_bilateral[\"participant_id\"]\n",
    "\n",
    "    \n",
    "    mask = ~X.isna().any(axis=1)\n",
    "    X, y, groups = X[mask], y[mask], groups[mask]\n",
    "\n",
    "    return X.values, y.values, groups.values, bilateral_feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare bilateral data\n",
    "X_bilateral, y_bilateral, groups_bilateral, bilateral_cols = (\n",
    "    prepare_bilateral_features()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ceab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "results_2b = []\n",
    "\n",
    "#---------------------------------\n",
    "for model_name, model in models.items():\n",
    "    print(f\"  Running {model_name}...\", end=\" \", flush=True)\n",
    "    model_clone = clone(model)\n",
    "    result = evaluate_loso(X_bilateral, y_bilateral, groups_bilateral, model_clone)\n",
    "\n",
    "    results_2b.append(\n",
    "        {\n",
    "            \"config\": \"bilateral\",\n",
    "            \"model\": model_name,\n",
    "            \"accuracy\": result[\"accuracy\"],\n",
    "            \"f1_macro\": result[\"f1_macro\"],\n",
    "            \"auc\": result[\"auc\"],\n",
    "            \"n_features\": len(bilateral_cols),\n",
    "            \"n_samples\": len(y_bilateral),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    tn, fp, fn, tp = result[\"confusion_matrix\"].ravel()\n",
    "    sens = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    spec = tn / (tn + fp) if (tn + fp) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e285b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for wrist_type in [\"non-dominant\", \"dominant\"]:\n",
    "    X, y, groups, _ = prepare_combined_features_single_wrist(\"wrist_type\", wrist_type)\n",
    "    print(f\"\\n  {wrist_type.upper()}: {len(y)} samples\")\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model_clone = clone(model)\n",
    "        result = evaluate_loso(X, y, groups, model_clone)\n",
    "\n",
    "        results_2b.append(\n",
    "            {\n",
    "                \"config\": wrist_type,\n",
    "                \"model\": model_name,\n",
    "                \"accuracy\": result[\"accuracy\"],\n",
    "                \"f1_macro\": result[\"f1_macro\"],\n",
    "                \"auc\": result[\"auc\"],\n",
    "                \"n_features\": 87,\n",
    "                \"n_samples\": len(y),\n",
    "            }\n",
    "        )\n",
    "        print(f\"Acc={result['accuracy']:.3f}\")\n",
    "\n",
    "df_results_2b = pd.DataFrame(results_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dae49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in [\"KNN\", \"SVM\", \"XGBoost\"]:\n",
    "    nd_acc = df_results_2b[\n",
    "        (df_results_2b[\"config\"] == \"non-dominant\")\n",
    "        & (df_results_2b[\"model\"] == model_name)\n",
    "    ][\"accuracy\"].values[0]\n",
    "    d_acc = df_results_2b[\n",
    "        (df_results_2b[\"config\"] == \"dominant\") & (df_results_2b[\"model\"] == model_name)\n",
    "    ][\"accuracy\"].values[0]\n",
    "    bi_acc = df_results_2b[\n",
    "        (df_results_2b[\"config\"] == \"bilateral\")\n",
    "        & (df_results_2b[\"model\"] == model_name)\n",
    "    ][\"accuracy\"].values[0]\n",
    "\n",
    "    best_single = max(nd_acc, d_acc)\n",
    "    best_wrist = \"ND\" if nd_acc > d_acc else \"D\"\n",
    "    improvement = bi_acc - best_single\n",
    "    status = (\n",
    "        \"BETTER\" if improvement > 0.005 else \"WORSE\" if improvement < -0.005 else \"SAME\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"{model_name:<12} {nd_acc:<10.3f} {d_acc:<10.3f} {bi_acc:<10.3f} \"\n",
    "        f\"{best_single:.3f} ({best_wrist})    {improvement:+.3f} ({status})\"\n",
    "    )\n",
    "    \n",
    "#---------------------------------\n",
    "nd_avg = df_results_2b[df_results_2b[\"config\"] == \"non-dominant\"][\"accuracy\"].mean()\n",
    "d_avg = df_results_2b[df_results_2b[\"config\"] == \"dominant\"][\"accuracy\"].mean()\n",
    "bi_avg = df_results_2b[df_results_2b[\"config\"] == \"bilateral\"][\"accuracy\"].mean()\n",
    "best_single_avg = max(nd_avg, d_avg)\n",
    "\n",
    "print(\n",
    "    f\"{'Average':<12} {nd_avg:<10.3f} {d_avg:<10.3f} {bi_avg:<10.3f} \"\n",
    "    f\"{best_single_avg:.3f}        {bi_avg - best_single_avg:+.3f}\"\n",
    ")\n",
    "\n",
    "#---------------------------------\n",
    "bilateral_wins = 0\n",
    "for model_name in [\"KNN\", \"SVM\", \"XGBoost\"]:\n",
    "    nd_acc = df_results_2b[\n",
    "        (df_results_2b[\"config\"] == \"non-dominant\")\n",
    "        & (df_results_2b[\"model\"] == model_name)\n",
    "    ][\"accuracy\"].values[0]\n",
    "    d_acc = df_results_2b[\n",
    "        (df_results_2b[\"config\"] == \"dominant\") & (df_results_2b[\"model\"] == model_name)\n",
    "    ][\"accuracy\"].values[0]\n",
    "    bi_acc = df_results_2b[\n",
    "        (df_results_2b[\"config\"] == \"bilateral\")\n",
    "        & (df_results_2b[\"model\"] == model_name)\n",
    "    ][\"accuracy\"].values[0]\n",
    "    if bi_acc > max(nd_acc, d_acc):\n",
    "        bilateral_wins += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d84600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bilateral, y_bilateral, groups_bilateral, bilateral_cols = (\n",
    "    prepare_bilateral_features()\n",
    ")\n",
    "df_bilateral_features = pd.DataFrame(X_bilateral, columns=bilateral_cols)\n",
    "\n",
    "\n",
    "bilateral_correlations = []\n",
    "\n",
    "for base_feature in (\n",
    "    eda_feature_cols + hr_feature_cols + temp_feature_cols + acc_feature_cols\n",
    "):\n",
    "    nd_col = f\"{base_feature}_ND\"\n",
    "    d_col = f\"{base_feature}_D\"\n",
    "\n",
    "    if (\n",
    "        nd_col in df_bilateral_features.columns\n",
    "        and d_col in df_bilateral_features.columns\n",
    "    ):\n",
    "        corr = df_bilateral_features[nd_col].corr(df_bilateral_features[d_col])\n",
    "\n",
    "\n",
    "        if base_feature.startswith(\"eda_\"):\n",
    "            signal = \"EDA\"\n",
    "        elif base_feature.startswith(\"hr_\"):\n",
    "            signal = \"HR\"\n",
    "        elif base_feature.startswith(\"temp_\"):\n",
    "            signal = \"TEMP\"\n",
    "        else:\n",
    "            signal = \"ACC\"\n",
    "\n",
    "        bilateral_correlations.append(\n",
    "            {\"feature\": base_feature, \"signal\": signal, \"correlation\": corr}\n",
    "        )\n",
    "\n",
    "df_bilateral_corr = pd.DataFrame(bilateral_correlations)\n",
    "\n",
    "#---------------------------------\n",
    "signal_corr = df_bilateral_corr.groupby(\"signal\")[\"correlation\"].agg(\n",
    "    [\"mean\", \"std\", \"min\", \"max\"]\n",
    ")\n",
    "print(signal_corr.round(3))\n",
    "#---------------------------------\n",
    "for signal in [\"EDA\", \"HR\", \"TEMP\", \"ACC\"]:\n",
    "    mean_corr = signal_corr.loc[signal, \"mean\"]\n",
    "    if mean_corr > 0.8:\n",
    "        interp = \"high\"\n",
    "    elif mean_corr > 0.5:\n",
    "        interp = \"modrate\"\n",
    "    else:\n",
    "        interp = \"low\"\n",
    "    print(f\"  {signal}: r={mean_corr:.3f} - {interp}\")\n",
    "\n",
    "\n",
    "low_corr = df_bilateral_corr.nsmallest(10, \"correlation\")\n",
    "for _, row in low_corr.iterrows():\n",
    "    print(f\"  {row['feature']:30s} [{row['signal']:4s}]: r={row['correlation']:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
