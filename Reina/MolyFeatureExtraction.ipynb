{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916dbf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy import signal as scipy_signal\n",
    "from scipy.fft import fft, fftfreq\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biosppy.signals import eda as biosppy_eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12433503",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FINAL_DIR = \"\"\n",
    "FEATURE_DIR = os.path.join(DATA_FINAL_DIR, \"Extracted_Features_Final\")\n",
    "os.makedirs(FEATURE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80e3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS_EDA = 4 \n",
    "FS_HR = 1  \n",
    "FS_TEMP = 1  \n",
    "FS_ACC = 63 \n",
    "WINDOW_SIZE_SEC = 60\n",
    "OVERLAP_SEC = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac23d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [f\"MIT{str(i).zfill(3)}\" for i in range(1, 26)]\n",
    "participants = [\n",
    "    p\n",
    "    for p in participants\n",
    "    if os.path.exists(os.path.join(DATA_FINAL_DIR, p, \"Filtered_Signals\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45cd7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_FINAL_DIR = \"\"\n",
    "\n",
    "pid = \"MIT001\"\n",
    "side = \"LEFT\"\n",
    "\n",
    "signals = {\n",
    "    \"EDA\": {\n",
    "        \"raw_path\": os.path.join(\n",
    "            DATA_FINAL_DIR, pid, \"Signals\", f\"{pid}_{side}_eda.csv\"\n",
    "        ),\n",
    "        \"filtered_path\": os.path.join(\n",
    "            DATA_FINAL_DIR, pid, \"Filtered_Signals\", f\"{pid}_{side}_eda_filtered.csv\"\n",
    "        ),\n",
    "        \"expected_fs\": 4,\n",
    "    },\n",
    "    \"HR\": {\n",
    "        \"raw_path\": os.path.join(\n",
    "            DATA_FINAL_DIR, pid, \"Signals\", f\"{pid}_{side}_hr.csv\"\n",
    "        ),\n",
    "        \"filtered_path\": None,  \n",
    "        \"expected_fs\": 1,\n",
    "    },\n",
    "    \"TEMP\": {\n",
    "        \"raw_path\": os.path.join(\n",
    "            DATA_FINAL_DIR, pid, \"Signals\", f\"{pid}_{side}_temp.csv\"\n",
    "        ),\n",
    "        \"filtered_path\": os.path.join(\n",
    "            DATA_FINAL_DIR, pid, \"Filtered_Signals\", f\"{pid}_{side}_temp_filtered.csv\"\n",
    "        ),\n",
    "        \"expected_fs\": 1,\n",
    "    },\n",
    "    \"ACC\": {\n",
    "        \"raw_path\": os.path.join(\n",
    "            DATA_FINAL_DIR, pid, \"Signals\", f\"{pid}_{side}_acc.csv\"\n",
    "        ),\n",
    "        \"filtered_path\": os.path.join(\n",
    "            DATA_FINAL_DIR, pid, \"Filtered_Signals\", f\"{pid}_{side}_acc_filtered.csv\"\n",
    "        ),\n",
    "        \"expected_fs\": 64,\n",
    "    },\n",
    "    \"BVP\": {\n",
    "        \"raw_path\": os.path.join(\n",
    "            DATA_FINAL_DIR, pid, \"Signals\", f\"{pid}_{side}_bvp.csv\"\n",
    "        ),\n",
    "        \"filtered_path\": None,\n",
    "        \"expected_fs\": 64,\n",
    "    },\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for signal_name, paths in signals.items():\n",
    "    print(f\"{signal_name}:\")\n",
    "\n",
    "    if os.path.exists(paths[\"raw_path\"]):\n",
    "        df_raw = pd.read_csv(paths[\"raw_path\"])\n",
    "        df_raw[\"ts\"] = pd.to_datetime(df_raw[\"timestamp\"])\n",
    "        duration_raw = (df_raw[\"ts\"].iloc[-1] - df_raw[\"ts\"].iloc[0]).total_seconds()\n",
    "        fs_raw = len(df_raw) / duration_raw\n",
    "\n",
    "\n",
    "        time_diff = df_raw[\"ts\"].diff().dt.total_seconds().dropna()\n",
    "\n",
    "    # Check FILTERED\n",
    "    if paths[\"filtered_path\"] and os.path.exists(paths[\"filtered_path\"]):\n",
    "        df_filt = pd.read_csv(paths[\"filtered_path\"])\n",
    "        df_filt[\"ts\"] = pd.to_datetime(df_filt[\"timestamp\"])\n",
    "        duration_filt = (df_filt[\"ts\"].iloc[-1] - df_filt[\"ts\"].iloc[0]).total_seconds()\n",
    "        fs_filt = len(df_filt) / duration_filt\n",
    "\n",
    "        print(f\"samples: {len(df_filt):,}\")\n",
    "        print(f\"calculated Fs: {fs_filt:.2f} Hz\")\n",
    "        print(f\"sample match: {len(df_raw) == len(df_filt)}\")\n",
    "    else:\n",
    "        fs_filt = None\n",
    "\n",
    "\n",
    "    actual_fs = fs_raw if fs_raw else fs_filt\n",
    "    expected = paths[\"expected_fs\"]\n",
    "    match = \"match \" if actual_fs and abs(actual_fs - expected) < 1 else \"no\"\n",
    "    print(f\"expect: {expected} Hz, actual: {actual_fs:.2f} Hz ~~ {match}\")\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"signal\": signal_name,\n",
    "            \"expected_fs\": expected,\n",
    "            \"actual_fs\": round(actual_fs, 2) if actual_fs else None,\n",
    "            \"match\": match,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "df_summary = pd.DataFrame(results)\n",
    "print(df_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03179e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_samples = WINDOW_SIZE_SEC * FS_HR  \n",
    "step_samples = OVERLAP_SEC * FS_HR  \n",
    "\n",
    "all_hr_features = []\n",
    "\n",
    "for participant_id in participants:\n",
    "    for side in [\"LEFT\", \"RIGHT\"]:\n",
    "\n",
    "        hr_path = os.path.join(\n",
    "            DATA_FINAL_DIR, participant_id, \"Signals\", f\"{participant_id}_{side}_hr.csv\"\n",
    "        )\n",
    "\n",
    "        if not os.path.exists(hr_path):\n",
    "            continue\n",
    "\n",
    "        df_hr = pd.read_csv(hr_path)\n",
    "        phases = df_hr[\"phase\"].dropna().unique()\n",
    "\n",
    "        for phase in phases:\n",
    "            phase_data = df_hr[df_hr[\"phase\"] == phase].reset_index(drop=True)\n",
    "\n",
    "            if len(phase_data) < window_samples:\n",
    "                continue\n",
    "\n",
    "            window_idx = 0\n",
    "            for start in range(0, len(phase_data) - window_samples + 1, step_samples):\n",
    "                end = start + window_samples\n",
    "                window = phase_data.iloc[start:end]\n",
    "\n",
    "                hr_vals = window[\"hr\"].values\n",
    "                hr_valid = hr_vals[(hr_vals >= 40) & (hr_vals <= 200)]\n",
    "\n",
    "                features = {\n",
    "                    \"participant_id\": participant_id,\n",
    "                    \"side\": side,\n",
    "                    \"phase\": phase,\n",
    "                    \"window_idx\": window_idx,\n",
    "                    \"window_start\": window[\"timestamp\"].iloc[0],\n",
    "                    \"window_end\": window[\"timestamp\"].iloc[-1],\n",
    "                }\n",
    "\n",
    "                if len(hr_valid) >= 5:\n",
    "                    # Basic statistics\n",
    "                    features[\"hr_mean\"] = np.mean(hr_valid)\n",
    "                    features[\"hr_std\"] = np.std(hr_valid)\n",
    "                    features[\"hr_min\"] = np.min(hr_valid)\n",
    "                    features[\"hr_max\"] = np.max(hr_valid)\n",
    "                    features[\"hr_range\"] = np.ptp(hr_valid)\n",
    "                    features[\"hr_median\"] = np.median(hr_valid)\n",
    "                    features[\"hr_iqr\"] = np.percentile(hr_valid, 75) - np.percentile(\n",
    "                        hr_valid, 25\n",
    "                    )\n",
    "                    features[\"hr_cv\"] = (\n",
    "                        (features[\"hr_std\"] / features[\"hr_mean\"]) * 100\n",
    "                        if features[\"hr_mean\"] > 0\n",
    "                        else 0\n",
    "                    )\n",
    "\n",
    "                \n",
    "                    rr_intervals = 60000 / hr_valid  \n",
    "                    rr_diff = np.diff(rr_intervals)\n",
    "\n",
    "                    features[\"hr_rmssd\"] = (\n",
    "                        np.sqrt(np.mean(rr_diff**2)) if len(rr_diff) > 0 else np.nan\n",
    "                    )\n",
    "                    features[\"hr_sdsd\"] = (\n",
    "                        np.std(rr_diff) if len(rr_diff) > 0 else np.nan\n",
    "                    )\n",
    "                    features[\"hr_pnn50\"] = (\n",
    "                        (np.sum(np.abs(rr_diff) > 50) / len(rr_diff)) * 100\n",
    "                        if len(rr_diff) > 0\n",
    "                        else np.nan\n",
    "                    )\n",
    "                    features[\"hr_pnn20\"] = (\n",
    "                        (np.sum(np.abs(rr_diff) > 20) / len(rr_diff)) * 100\n",
    "                        if len(rr_diff) > 0\n",
    "                        else np.nan\n",
    "                    )\n",
    "                    features[\"hr_sdnn\"] = np.std(rr_intervals)\n",
    "                    features[\"hr_mean_rr\"] = np.mean(rr_intervals)\n",
    "                else:\n",
    "                    for col in [\n",
    "                        \"hr_mean\",\n",
    "                        \"hr_std\",\n",
    "                        \"hr_min\",\n",
    "                        \"hr_max\",\n",
    "                        \"hr_range\",\n",
    "                        \"hr_median\",\n",
    "                        \"hr_iqr\",\n",
    "                        \"hr_cv\",\n",
    "                        \"hr_rmssd\",\n",
    "                        \"hr_sdsd\",\n",
    "                        \"hr_pnn50\",\n",
    "                        \"hr_pnn20\",\n",
    "                        \"hr_sdnn\",\n",
    "                        \"hr_mean_rr\",\n",
    "                    ]:\n",
    "                        features[col] = np.nan\n",
    "\n",
    "                all_hr_features.append(features)\n",
    "                window_idx += 1\n",
    "\n",
    "    print(f\"  {participant_id} done\")\n",
    "\n",
    "df_hr_features = pd.DataFrame(all_hr_features)\n",
    "df_hr_features.to_csv(os.path.join(FEATURE_DIR, \"features_hr.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deab9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_samples = WINDOW_SIZE_SEC * FS_TEMP  \n",
    "step_samples = OVERLAP_SEC * FS_TEMP  \n",
    "\n",
    "all_temp_features = []\n",
    "\n",
    "for participant_id in participants:\n",
    "    for side in [\"LEFT\", \"RIGHT\"]:\n",
    "\n",
    "        temp_path = os.path.join(\n",
    "            DATA_FINAL_DIR,\n",
    "            participant_id,\n",
    "            f\"{participant_id}_{side}_temp_filtered.csv\",\n",
    "        )\n",
    "\n",
    "        if not os.path.exists(temp_path):\n",
    "            continue\n",
    "\n",
    "        df_temp = pd.read_csv(temp_path)\n",
    "        phases = df_temp[\"phase\"].dropna().unique()\n",
    "\n",
    "        for phase in phases:\n",
    "            phase_data = df_temp[df_temp[\"phase\"] == phase].reset_index(drop=True)\n",
    "\n",
    "            if len(phase_data) < window_samples:\n",
    "                continue\n",
    "\n",
    "            window_idx = 0\n",
    "            for start in range(0, len(phase_data) - window_samples + 1, step_samples):\n",
    "                end = start + window_samples\n",
    "                window = phase_data.iloc[start:end]\n",
    "\n",
    "                temp_vals = window[\"temp_filtered\"].values\n",
    "\n",
    "                features = {\n",
    "                    \"participant_id\": participant_id,\n",
    "                    \"side\": side,\n",
    "                    \"phase\": phase,\n",
    "                    \"window_idx\": window_idx,\n",
    "                    \"window_start\": window[\"timestamp\"].iloc[0],\n",
    "                    \"window_end\": window[\"timestamp\"].iloc[-1],\n",
    "                }\n",
    "                features[\"temp_mean\"] = np.mean(temp_vals)\n",
    "                features[\"temp_std\"] = np.std(temp_vals)\n",
    "                features[\"temp_min\"] = np.min(temp_vals)\n",
    "                features[\"temp_max\"] = np.max(temp_vals)\n",
    "                features[\"temp_range\"] = np.ptp(temp_vals)\n",
    "                features[\"temp_median\"] = np.median(temp_vals)\n",
    "                features[\"temp_iqr\"] = np.percentile(temp_vals, 75) - np.percentile(\n",
    "                    temp_vals, 25\n",
    "                )\n",
    "                features[\"temp_skewness\"] = stats.skew(temp_vals)\n",
    "                features[\"temp_kurtosis\"] = stats.kurtosis(temp_vals)\n",
    "\n",
    "                #trend \n",
    "                x = np.arange(len(temp_vals))\n",
    "                slope, _ = np.polyfit(x, temp_vals, 1)\n",
    "                features[\"temp_slope\"] = slope\n",
    "\n",
    "                #derivaive\n",
    "                temp_diff = np.diff(temp_vals)\n",
    "                features[\"temp_mean_diff\"] = np.mean(np.abs(temp_diff))\n",
    "                features[\"temp_std_diff\"] = np.std(temp_diff)\n",
    "\n",
    "                all_temp_features.append(features)\n",
    "                window_idx += 1\n",
    "\n",
    "    print(f\"{participant_id} done\")\n",
    "\n",
    "df_temp_features = pd.DataFrame(all_temp_features)\n",
    "df_temp_features.to_csv(os.path.join(FEATURE_DIR, \"features_temp.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb1ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_samples = WINDOW_SIZE_SEC * FS_ACC  # 60 * 63 = 3780\n",
    "step_samples = OVERLAP_SEC * FS_ACC  # 30 * 63 = 1890\n",
    "all_acc_features = []\n",
    "\n",
    "for participant_id in participants:\n",
    "    for side in [\"LEFT\", \"RIGHT\"]:\n",
    "\n",
    "        acc_path = os.path.join(\n",
    "            DATA_FINAL_DIR,\n",
    "            participant_id,\n",
    "            f\"{participant_id}_{side}_acc_filtered.csv\",\n",
    "        )\n",
    "\n",
    "        if not os.path.exists(acc_path):\n",
    "            continue\n",
    "\n",
    "        df_acc = pd.read_csv(acc_path)\n",
    "        phases = df_acc[\"phase\"].dropna().unique()\n",
    "\n",
    "        for phase in phases:\n",
    "            phase_data = df_acc[df_acc[\"phase\"] == phase].reset_index(drop=True)\n",
    "\n",
    "            if len(phase_data) < window_samples:\n",
    "                continue\n",
    "\n",
    "            window_idx = 0\n",
    "            for start in range(0, len(phase_data) - window_samples + 1, step_samples):\n",
    "                end = start + window_samples\n",
    "                window = phase_data.iloc[start:end]\n",
    "\n",
    "                features = {\n",
    "                    \"participant_id\": participant_id,\n",
    "                    \"side\": side,\n",
    "                    \"phase\": phase,\n",
    "                    \"window_idx\": window_idx,\n",
    "                    \"window_start\": window[\"timestamp\"].iloc[0],\n",
    "                    \"window_end\": window[\"timestamp\"].iloc[-1],\n",
    "                }\n",
    "\n",
    "                acc_x = window[\"acc_x_filtered\"].values\n",
    "                acc_y = window[\"acc_y_filtered\"].values\n",
    "                acc_z = window[\"acc_z_filtered\"].values\n",
    "\n",
    "                for axis, vals in [(\"x\", acc_x), (\"y\", acc_y), (\"z\", acc_z)]:\n",
    "                    features[f\"acc_{axis}_mean\"] = np.mean(vals)\n",
    "                    features[f\"acc_{axis}_std\"] = np.std(vals)\n",
    "                    features[f\"acc_{axis}_min\"] = np.min(vals)\n",
    "                    features[f\"acc_{axis}_max\"] = np.max(vals)\n",
    "                    features[f\"acc_{axis}_range\"] = np.ptp(vals)\n",
    "                    features[f\"acc_{axis}_iqr\"] = np.percentile(\n",
    "                        vals, 75\n",
    "                    ) - np.percentile(vals, 25)\n",
    "\n",
    "                magnitude = np.sqrt(acc_x**2 + acc_y**2 + acc_z**2)\n",
    "                features[\"acc_magnitude_mean\"] = np.mean(magnitude)\n",
    "                features[\"acc_magnitude_std\"] = np.std(magnitude)\n",
    "                features[\"acc_magnitude_max\"] = np.max(magnitude)\n",
    "                features[\"acc_magnitude_range\"] = np.ptp(magnitude)\n",
    "\n",
    "                # ENMO\n",
    "                if \"enmo\" in window.columns:\n",
    "                    enmo = window[\"enmo\"].values\n",
    "                else:\n",
    "                    if \"acc_x_raw\" in window.columns:\n",
    "                        mag_raw = np.sqrt(\n",
    "                            window[\"acc_x_raw\"] ** 2\n",
    "                            + window[\"acc_y_raw\"] ** 2\n",
    "                            + window[\"acc_z_raw\"] ** 2\n",
    "                        )\n",
    "                        enmo = np.clip(mag_raw - 1.0, 0, None)\n",
    "                    else:\n",
    "                        enmo = np.clip(magnitude - 1.0, 0, None)\n",
    "\n",
    "                features[\"acc_enmo_mean\"] = np.mean(enmo)\n",
    "                features[\"acc_enmo_std\"] = np.std(enmo)\n",
    "                features[\"acc_enmo_max\"] = np.max(enmo)\n",
    "                features[\"acc_enmo_sum\"] = np.sum(enmo)\n",
    "\n",
    "                features[\"acc_activity_level\"] = np.var(magnitude)\n",
    "\n",
    "                features[\"acc_sma\"] = (\n",
    "                    np.sum(np.abs(acc_x))\n",
    "                    + np.sum(np.abs(acc_y))\n",
    "                    + np.sum(np.abs(acc_z))\n",
    "                ) / len(acc_x)\n",
    "\n",
    "                var_x, var_y, var_z = np.var(acc_x), np.var(acc_y), np.var(acc_z)\n",
    "                total_var = var_x + var_y + var_z\n",
    "\n",
    "                if total_var > 0:\n",
    "                    features[\"acc_x_dominance\"] = var_x / total_var\n",
    "                    features[\"acc_y_dominance\"] = var_y / total_var\n",
    "                    features[\"acc_z_dominance\"] = var_z / total_var\n",
    "                else:\n",
    "                    features[\"acc_x_dominance\"] = 0.33\n",
    "                    features[\"acc_y_dominance\"] = 0.33\n",
    "                    features[\"acc_z_dominance\"] = 0.33\n",
    "\n",
    "                all_acc_features.append(features)\n",
    "                window_idx += 1\n",
    "\n",
    "    print(f\"  {participant_id} done\")\n",
    "\n",
    "df_acc_features = pd.DataFrame(all_acc_features)\n",
    "df_acc_features.to_csv(os.path.join(FEATURE_DIR, \"features_acc.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
